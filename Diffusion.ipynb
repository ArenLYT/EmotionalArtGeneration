{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4432fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import diffusers\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import accelerate\n",
    "#import pytorch_msssim\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline, DDIMScheduler,StableDiffusionPipeline,DPMSolverMultistepScheduler\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8874d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('ArtEmisv1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2144a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modo(x):\n",
    "    if  x.value_counts()[0]>=sum(x.value_counts())*1.0 :\n",
    "        return pd.Series.mode(x)\n",
    "    else:\n",
    "        return x.value_counts()[:3].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5173b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emtype(x):\n",
    "    if x.emotion=='sadness':\n",
    "        return \"negative\"\n",
    "    elif x.emotion=='fear':\n",
    "        return \"negative\"\n",
    "    elif x.emotion=='disgust':\n",
    "        return \"negative\"\n",
    "    elif x.emotion=='anger':\n",
    "        return \"negative\"\n",
    "    elif x.emotion=='contentment':\n",
    "        return \"positive\"\n",
    "    elif x.emotion=='awe':\n",
    "        return \"positive\"\n",
    "    elif x.emotion=='amusement':\n",
    "        return \"positive\"\n",
    "    elif x.emotion=='excitement':\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"something else\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b8f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfemo=df\n",
    "dfemo['emotype']= dfemo.apply(emtype,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d51ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfemo=dfemo.groupby([\"art_style\",\"painting\"])[\"emotype\"].agg(modo).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57aca6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=type(dfemo.emotype[0])\n",
    "dfemo=dfemo[dfemo[\"emotype\"].apply(lambda x: type(x) !=t )].reset_index()\n",
    "dfemo = dfemo.drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d01981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfemo=dfemo[dfemo.emotype!=\"something else\"].reset_index()\n",
    "dfemo = dfemo.drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a43569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfemo['path']= dfemo.apply(lambda x: 'dataset\\\\wikiart\\\\'+x['art_style']+\"\\\\\"+ x['painting']+\".jpg\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "821e39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frac=1-(dfemo.emotype.value_counts()[1]/dfemo.emotype.value_counts()[0])\n",
    "\n",
    "#dfemo = dfemo.drop(dfemo[dfemo['emotype'] == \"positive\"].sample(frac=frac).index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fde6b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Classes')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(dfemo.emotype,bins=range(0,3), rwidth=0.8,align=\"left\")\n",
    "plt.title('Histogram of Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a47fedf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_style</th>\n",
       "      <th>painting</th>\n",
       "      <th>emotype</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism</td>\n",
       "      <td>aaron-siskind_yuchitan-1-1955</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Abstract_Expressionism\\aaron-siskind_yuchitan-1-1955.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism</td>\n",
       "      <td>aki-kuroda_conti-nuit-1979</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Abstract_Expressionism\\aki-kuroda_conti-nuit-1979.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abstract_Expressionism</td>\n",
       "      <td>atsuko-tanaka_93e-1993</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Abstract_Expressionism\\atsuko-tanaka_93e-1993.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Abstract_Expressionism</td>\n",
       "      <td>clyfford-still_1947-r-no-1-1947</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Abstract_Expressionism\\clyfford-still_1947-r-no-1-1947.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Abstract_Expressionism</td>\n",
       "      <td>clyfford-still_ph-385-1949-no-1-1949</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Abstract_Expressionism\\clyfford-still_ph-385-1949-no-1-1949.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16705</th>\n",
       "      <td>Ukiyo_e</td>\n",
       "      <td>utagawa-kuniyoshi_sotoku-invoking-a-thunder-storm</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_sotoku-invoking-a-thunder-storm.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16707</th>\n",
       "      <td>Ukiyo_e</td>\n",
       "      <td>utagawa-kuniyoshi_tametomo-rescued-from-the-sea-monster-by-tengu</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_tametomo-rescued-from-the-sea-monster-by-tengu.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16710</th>\n",
       "      <td>Ukiyo_e</td>\n",
       "      <td>utagawa-kuniyoshi_the-actor-15</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-actor-15.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16713</th>\n",
       "      <td>Ukiyo_e</td>\n",
       "      <td>utagawa-kuniyoshi_the-ghost-in-the-lantern</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-ghost-in-the-lantern.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>Ukiyo_e</td>\n",
       "      <td>utagawa-kuniyoshi_the-hundred-and-eight-heroes-of-the-popular-suikoden-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-hundred-and-eight-heroes-of-the-popular-suikoden-1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1833 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    art_style  \\\n",
       "0      Abstract_Expressionism   \n",
       "1      Abstract_Expressionism   \n",
       "11     Abstract_Expressionism   \n",
       "22     Abstract_Expressionism   \n",
       "23     Abstract_Expressionism   \n",
       "...                       ...   \n",
       "16705                 Ukiyo_e   \n",
       "16707                 Ukiyo_e   \n",
       "16710                 Ukiyo_e   \n",
       "16713                 Ukiyo_e   \n",
       "16714                 Ukiyo_e   \n",
       "\n",
       "                                                                       painting  \\\n",
       "0                                                 aaron-siskind_yuchitan-1-1955   \n",
       "1                                                    aki-kuroda_conti-nuit-1979   \n",
       "11                                                       atsuko-tanaka_93e-1993   \n",
       "22                                              clyfford-still_1947-r-no-1-1947   \n",
       "23                                         clyfford-still_ph-385-1949-no-1-1949   \n",
       "...                                                                         ...   \n",
       "16705                         utagawa-kuniyoshi_sotoku-invoking-a-thunder-storm   \n",
       "16707          utagawa-kuniyoshi_tametomo-rescued-from-the-sea-monster-by-tengu   \n",
       "16710                                            utagawa-kuniyoshi_the-actor-15   \n",
       "16713                                utagawa-kuniyoshi_the-ghost-in-the-lantern   \n",
       "16714  utagawa-kuniyoshi_the-hundred-and-eight-heroes-of-the-popular-suikoden-1   \n",
       "\n",
       "        emotype  \\\n",
       "0      negative   \n",
       "1      negative   \n",
       "11     negative   \n",
       "22     negative   \n",
       "23     negative   \n",
       "...         ...   \n",
       "16705  negative   \n",
       "16707  negative   \n",
       "16710  negative   \n",
       "16713  negative   \n",
       "16714  negative   \n",
       "\n",
       "                                                                                                       path  \n",
       "0                                  dataset\\wikiart\\Abstract_Expressionism\\aaron-siskind_yuchitan-1-1955.jpg  \n",
       "1                                     dataset\\wikiart\\Abstract_Expressionism\\aki-kuroda_conti-nuit-1979.jpg  \n",
       "11                                        dataset\\wikiart\\Abstract_Expressionism\\atsuko-tanaka_93e-1993.jpg  \n",
       "22                               dataset\\wikiart\\Abstract_Expressionism\\clyfford-still_1947-r-no-1-1947.jpg  \n",
       "23                          dataset\\wikiart\\Abstract_Expressionism\\clyfford-still_ph-385-1949-no-1-1949.jpg  \n",
       "...                                                                                                     ...  \n",
       "16705                         dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_sotoku-invoking-a-thunder-storm.jpg  \n",
       "16707          dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_tametomo-rescued-from-the-sea-monster-by-tengu.jpg  \n",
       "16710                                            dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-actor-15.jpg  \n",
       "16713                                dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-ghost-in-the-lantern.jpg  \n",
       "16714  dataset\\wikiart\\Ukiyo_e\\utagawa-kuniyoshi_the-hundred-and-eight-heroes-of-the-popular-suikoden-1.jpg  \n",
       "\n",
       "[1833 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfemo[dfemo[\"emotype\"]==\"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c506bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = np.max([w, h])\n",
    "        hp = int((max_wh - w) / 2)\n",
    "        vp = int((max_wh - h) / 2)\n",
    "        padding = (hp, vp, hp, vp)\n",
    "        return torchvision.transforms.functional.pad(image, padding, 255, 'constant')\n",
    "\n",
    "# now use it as the replacement of transforms.Pad class\n",
    "transform=torchvision.transforms.Compose([\n",
    "    SquarePad(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(256),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=torchvision.datasets.ImageFolder(root=\"diffset\",transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed it into a dataloader (batch size 8 here just for demo)\n",
    "train_dataloader = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "\n",
    "# View some examples\n",
    "x, y = next(iter(train_dataloader))\n",
    "print('Input shape:', x.shape)\n",
    "print('Labels:', y)\n",
    "plt.imshow(torchvision.utils.make_grid(x).permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7630071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/huggingface/diffusion-models-class/blob/main/unit2/02_class_conditioned_diffusion_model_example.ipynb\n",
    "class ClassConditionedUnet(nn.Module):\n",
    "  def __init__(self, num_classes=2, class_emb_size=2):\n",
    "    super().__init__()\n",
    "    \n",
    "    # The embedding layer will map the class label to a vector of size class_emb_size\n",
    "    self.class_emb = nn.Embedding(num_classes, class_emb_size)\n",
    "\n",
    "    # Self.model is an unconditional UNet with extra input channels to accept the conditioning information (the class embedding)\n",
    "    self.model = UNet2DModel(\n",
    "        sample_size=256,           # the target image resolution\n",
    "        in_channels=3 + class_emb_size, # Additional input channels for class cond.\n",
    "        out_channels=3,           # the number of output channels\n",
    "        layers_per_block=4,       # how many ResNet layers to use per UNet block\n",
    "        block_out_channels=(128, 128, 256,256,512,512), \n",
    "        down_block_types=( \n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "        ), \n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\", \n",
    "            \"AttnUpBlock2D\", \n",
    "            \"UpBlock2D\",      \n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\", \n",
    "            \"UpBlock2D\",\n",
    "          ),\n",
    "    )\n",
    "\n",
    "  # Our forward method now takes the class labels as an additional argument\n",
    "  def forward(self, x, t, class_labels):\n",
    "    # Shape of x:\n",
    "    bs, ch, w, h = x.shape\n",
    "    \n",
    "    # class conditioning in right shape to add as additional input channels\n",
    "    class_cond = self.class_emb(class_labels) # Map to embedding dinemsion\n",
    "    class_cond = class_cond.view(bs, class_cond.shape[1], 1, 1).expand(bs, class_cond.shape[1], w, h)\n",
    "    # x is shape (bs, 1, 28, 28) and class_cond is now (bs, 4, 28, 28)\n",
    "\n",
    "    # Net input is now x and class cond concatenated together along dimension 1\n",
    "    net_input = torch.cat((x, class_cond), 1) # (bs, 5, 28, 28)\n",
    "\n",
    "    # Feed this to the unet alongside the timestep and return the prediction\n",
    "    return self.model(net_input, t).sample # (bs, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c31edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a scheduler\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=500, beta_schedule='squaredcos_cap_v2')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the dataloader to set the batch size higher than the demo of 8\n",
    "train_dataloader = DataLoader(ds, batch_size=4, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epochs = 10\n",
    "\n",
    "# Our network \n",
    "net = ClassConditionedUnet().to(\"cuda\")\n",
    "\n",
    "# Our loss finction\n",
    "loss_fn = pytorch_msssim.SSIM()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-5) \n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []\n",
    "\n",
    "# The training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        \n",
    "        # Get some data and prepare the corrupted version\n",
    "        x = x.to(\"cuda\")*2-1  # Data on the GPU (mapped to (-1, 1))\n",
    "        y = y.to(\"cuda\")\n",
    "        noise = torch.randn_like(x)\n",
    "        #timesteps = torch.randint(0, 999, (x.shape[0],)).long().to(\"cuda\")\n",
    "        timesteps=torch.randint(0, noise_scheduler.num_train_timesteps, (x.shape[0],)).long().to(\"cuda\")\n",
    "        noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n",
    "        \n",
    "        # Get the model prediction\n",
    "        \n",
    "        pred = net(noisy_x, timesteps,y) # Note that we pass in the labels y\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = F.mse_loss(pred,noise)+(1-loss_fn(pred,noise)) # How close is the output to the noise\n",
    "        #loss=F.mse_loss(pred,noise)\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Store the loss for later\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Print our the average of the last 100 loss values to get an idea of progress:\n",
    "    avg_loss = sum(losses[-100:])/100\n",
    "    print(f'Finished epoch {epoch}. Average of the last 100 loss values: {avg_loss:05f}')\n",
    "\n",
    "# View the loss curve\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b90dd-7fe7-4fbf-8cb2-f78a68fd196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,r\"D://EmotionalArtGeneration//epoch10ssim.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36293a15-a315-460f-a9c0-62c9bf2b09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "netload=torch.load(\"D://EmotionalArtGeneration//epoch10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc1ddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065916618861410fac9a6ec04a35d8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0dfc41176f4689bf17eabc7332d8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dce97cced446e9a6506e4d77e084d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014906dbe4504ce0ac44b263e453d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835eea5c83de4697a6c44f45b816b2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052c72bc2db648b0b7a004e21fa7171b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c3e8e86d094a63ab0a0108eceb5020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df8d690a7ac43c18245285a293e2c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d208336de04d5a986dc81e989388bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faddaf42b194a04a0ba19b8b29bc318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74decc078418419bbe5ba395c1a0c70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29afcab88d444ef581f1f8cee19c6d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ce0e03715c48968726b13145ec0ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4630816255946318d63256498982836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0965c1a023ed47778e03cc4e94fe3273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5061b8cacce6408fb689f6b53f411a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656f8a75e301483ea77782e0359f23f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf31a75665e479b957bbf205db8ddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468ba0cb5d5c46dd8c57ffee7412a615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11d97f64b204e0b9468c41948b5dc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in range(20):\n",
    "    # Prepare random x to start from, plus some desired labels y\n",
    "    x = torch.randn(10, 3, 256, 256).to('cuda')\n",
    "    y = torch.tensor([[i]*5 for i in range(2)]).flatten().to('cuda')\n",
    "    # Sampling loop\n",
    "    for i, t in tqdm(enumerate(noise_scheduler.timesteps)):\n",
    "    \n",
    "        # Get model pred\n",
    "        with torch.no_grad():\n",
    "            residual = netload(x, t,y)  # Again, note that we pass in our labels y\n",
    "    \n",
    "        # Update sample with step\n",
    "        x = noise_scheduler.step(residual, t, x).prev_sample\n",
    "    z=(x+1)/2\n",
    "    p=z.detach().cpu()\n",
    "    for k in range(p.shape[0]):\n",
    "        #result=Image.fromarray(p[i].permute(1,2,0))\n",
    "        if k<5:\n",
    "            torchvision.utils.save_image(p[k],\"results//negative//\"+str(k+(j*10))+\".png\")\n",
    "            #result.save(\"results//negative//\"+str(i)+\".png\")\n",
    "        else:\n",
    "            torchvision.utils.save_image(p[k],\"results//positive//\"+str(k+j*10)+\".png\")\n",
    "            #result.save(\"results//positive//\"+str(i)+\".png\")\n",
    "        \n",
    "# Show the results\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(48, 48))\n",
    "#ax.imshow(torchvision.utils.make_grid(x.detach().cpu().clip(0, 255), nrow=8).permute(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
